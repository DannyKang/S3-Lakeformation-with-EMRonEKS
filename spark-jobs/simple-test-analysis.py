#!/usr/bin/env python3
"""
Simple Test Analysis - Lake Formation ì—†ì´ ê¸°ë³¸ Glue Catalog í…ŒìŠ¤íŠ¸
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import sys

def create_spark_session():
    """ê¸°ë³¸ Spark ì„¸ì…˜ ìƒì„± (Lake Formation FGAC ë¹„í™œì„±í™”)"""
    return SparkSession.builder \
        .appName("Simple-Glue-Catalog-Test") \
        .getOrCreate()

def main():
    print("=== Simple Glue Catalog Test ì‹œì‘ ===")
    print("Lake Formation FGAC ë¹„í™œì„±í™” ìƒíƒœì—ì„œ í…ŒìŠ¤íŠ¸")
    
    spark = create_spark_session()
    
    try:
        # ê¸°ë³¸ Glue Catalogë¥¼ í†µí•´ ë°ì´í„° ì½ê¸°
        print("\n1. Glue Catalogë¥¼ í†µí•´ ë°ì´í„° ë¡œë“œ ì¤‘...")
        namespace = "bike_db"
        table_name = "bike_rental_data"
        
        print(f"   ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
        print(f"   í…Œì´ë¸”ëª…: {table_name}")
        print(f"   ì¹´íƒˆë¡œê·¸: glue_catalog.{namespace}.{table_name}")
        
        # Glue ì¹´íƒˆë¡œê·¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ í…Œì´ë¸” ë°ì´í„° ì½ê¸°
        df = spark.table(f"glue_catalog.{namespace}.{table_name}")
        
        total_records = df.count()
        print(f"âœ… ì´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê±´")
        
        # ë°ì´í„° ìŠ¤í‚¤ë§ˆ í™•ì¸
        print("\n2. ë°ì´í„° ìŠ¤í‚¤ë§ˆ:")
        df.printSchema()
        
        # ê¸°ë³¸ í†µê³„
        print(f"\n3. ê¸°ë³¸ í†µê³„ ì •ë³´:")
        print(f"   â€¢ ê³ ìœ  ëŒ€ì—¬ ID: {df.select('rental_id').distinct().count():,}")
        print(f"   â€¢ ê³ ìœ  ì •ê±°ì¥: {df.select('station_id').distinct().count():,}")
        print(f"   â€¢ ê³ ìœ  êµ¬: {df.select('district').distinct().count()}")
        
        # êµ¬ë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ)
        print(f"\n4. êµ¬ë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ):")
        district_stats = df.groupBy("district") \
                           .agg(count("*").alias("count")) \
                           .orderBy(desc("count")) \
                           .limit(5)
        
        district_stats.show(truncate=False)
        
        # ì„±ë³„ ë¶„í¬
        print(f"\n5. ì„±ë³„ ë¶„í¬:")
        gender_stats = df.groupBy("gender") \
                         .agg(count("*").alias("count")) \
                         .orderBy(desc("count"))
        
        gender_stats.show()
        
        print(f"\n=== Simple Glue Catalog Test ì™„ë£Œ ===")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {total_records:,}ê±´")
        print(f"ğŸ”‘ ê¶Œí•œ: ê¸°ë³¸ Glue Catalog ì ‘ê·¼")
        print(f"ğŸ“Š ìƒíƒœ: Lake Formation FGAC ë¹„í™œì„±í™”")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    finally:
        spark.stop()

if __name__ == "__main__":
    main()
